{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "\n",
    "DATADIR=sys.path[0]+\"/Images\"\n",
    "\n",
    "CATEGORIES=np.arange(43)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "training_data = []\n",
    "IMG_SIZE = 80\n",
    "\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES:  \n",
    "\n",
    "        path = os.path.join(DATADIR,str(category))  \n",
    "        class_num=category\n",
    "        for img in tqdm(os.listdir(path)):  # iterate over each image per dogs and cats\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n",
    "                training_data.append([new_array, class_num])  # add this to our training_data\n",
    "            except Exception as e:  # in the interest in keeping the output clean...\n",
    "                pass\n",
    "\n",
    "create_training_data()\n"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'CATEGORIES' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9600/1247790997.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;31m#    print(\"general exception\", e, os.path.join(path,img))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mcreate_training_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_9600/1247790997.py\u001b[0m in \u001b[0;36mcreate_training_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_training_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mcategory\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mCATEGORIES\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# do dogs and cats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATADIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# create path to dogs and cats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CATEGORIES' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(training_data)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for features,label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "\n",
    "print(X[0].reshape(-1, IMG_SIZE, IMG_SIZE, 1))\n",
    "\n",
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 6400 into shape (50,50,1)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19593/1866424630.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 6400 into shape (50,50,1)"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "'''\n",
    "\n",
    "DO NOT RUN AGAIN\n",
    "\n",
    "DO NOT RUN AGAIN\n",
    "\n",
    "DO NOT RUN AGAIN\n",
    "\n",
    "DO NOT RUN AGAIN\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "import pickle\n",
    "\n",
    "pickle_out = open(\"X.pickle\",\"wb\")\n",
    "pickle.dump(X, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"y.pickle\",\"wb\")\n",
    "pickle.dump(y, pickle_out)\n",
    "pickle_out.close()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import pickle\n",
    "pickle_in = open(\"X.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_in)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "print(X.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(39209, 80, 80, 1)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "X=X/255.0\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "X=np.array(X)\n",
    "y=np.array(y)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "#print(X[0])\n",
    "print(y[134])\n",
    "IMG_SIZE=50\n",
    "new_array = cv2.resize(X[7], (IMG_SIZE, IMG_SIZE))\n",
    "plt.imshow(new_array, cmap='gray')\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "X_temp=X.copy()\n",
    "y_temp=y.copy()\n",
    "                                                                                                                                                                                                                                                                                                                                                                "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.33)\n",
    "y_train = to_categorical(y_train, 43)                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
    "y_val = to_categorical(y_val, 43)\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "X_train.shape[1:]\n",
    "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    "
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(80, 80, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu', input_shape=X_train.shape[1:]))\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "# We have 43 classes that's why we have defined 43 in the dense\n",
    "model.add(Dense(43, activation='softmax'))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-10-09 13:31:44.165983: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-09 13:31:44.166483: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-10-09 13:31:44.166606: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2021-10-09 13:31:44.166681: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2021-10-09 13:31:44.166753: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2021-10-09 13:31:44.166824: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2021-10-09 13:31:44.166894: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2021-10-09 13:31:44.166964: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2021-10-09 13:31:44.167033: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2021-10-09 13:31:44.167042: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1835] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-10-09 13:31:44.167440: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "\n",
    "history = model.fit_generator(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_val, y_val))\n"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "fit_generator() got an unexpected keyword argument 'batch_size'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9600/2554147428.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: fit_generator() got an unexpected keyword argument 'batch_size'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "model.save(\"./training/TSR.h5\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "model = load_model('./'+\"model.h5\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data_dir=sys.path[0]+\"/data\"\n",
    "test = pd.read_csv(data_dir + '/Test.csv')\n",
    "\n",
    "labels = test[\"ClassId\"].values\n",
    "imgs = test[\"Path\"].values\n",
    "\n",
    "data =[]\n",
    "\n",
    "IMG_SIZE=80\n",
    "for img in imgs:\n",
    "    try:\n",
    "        image = cv2.imread(data_dir + '/' +img,cv2.IMREAD_GRAYSCALE)\n",
    "        new_array = cv2.resize(image, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n",
    "        X_use=new_array \n",
    "        X_use = np.array(X_use).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "        use=X_use.copy()    \n",
    "        use=use.reshape(-1,80,80,1)\n",
    "        # image_fromarray = Image.fromarray(image, 'RGB')\n",
    "        # resize_image = image_fromarray.resize((IMG_SIZE, IMG_SIZE))\n",
    "        data.append(np.array(use))\n",
    "    except:\n",
    "        print(\"Error in \" + img)\n",
    "\n",
    "\n",
    "# #pred = model.predict_classes(X_test)\n",
    "# predict_x=model.predict(X_test)    \n",
    "# Y_pred=classes_x=np.argmax  (predict_x,axis=1)  \n",
    "# pred=Y_pred\n",
    "# #Accuracy with the test data\n",
    "# print('Test Data accuracy: ',accuracy_score(labels, pred)*100)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "print(data[0].shape)\n",
    "X_test = np.array(data)\n",
    "X_test = X_test/255\n",
    "print(X_test.shape)\n",
    "\n",
    "\n",
    "i=900\n",
    "#pred = model.predict_classes(X_test)\n",
    "predict_x=model.predict(data[i])    \n",
    "Y_pred=classes_x=np.argmax  (predict_x,axis=1)  \n",
    "pred=Y_pred\n",
    "#Accuracy with the test data\n",
    "#print('Test Data accuracy: ',accuracy_score(labels, pred)*100)\n",
    "image=data[i]\n",
    "plot,prediction=use,Y_pred  \n",
    "s = [str(i) for i in prediction] \n",
    "a = int(\"\".join(s)) \n",
    "print(\"---------------------PREDICTION------------------\")\n",
    "print(\"Predicted traffic sign is \",a)\n",
    "# new_arraytemp = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "# plt.imshow(new_arraytemp, cmap='gray')\n",
    "# plt.show()\n",
    "\n",
    "true_prediction=0\n",
    "false_prediction=0\n",
    "for i in range(0,len(data)):\n",
    "    pass\n",
    "    predict_x=model.predict(data[i])    \n",
    "    Y_pred=classes_x=np.argmax  (predict_x,axis=1)  \n",
    "    pred=Y_pred\n",
    "    #Accuracy with the test data\n",
    "    #print('Test Data accuracy: ',accuracy_score(labels, pred)*100)\n",
    "    image=data[i]\n",
    "    plot,prediction=use,Y_pred  \n",
    "    s = [str(i) for i in prediction] \n",
    "    a = int(\"\".join(s))\n",
    "    if(a==labels[i]):\n",
    "        true_prediction+=1\n",
    "    else:\n",
    "        false_prediction+=1\n",
    "    pass\n",
    "\n",
    "print(true_prediction/len(data))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1, 80, 80, 1)\n",
      "(12630, 1, 80, 80, 1)\n",
      "---------------------PREDICTION------------------\n",
      "Predicted traffic sign is  11\n",
      "0.9054631828978622\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "print(\"test accuracy=\",true_prediction/len(data) *100,\"%\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "test accuracy= 90.54631828978621 %\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}